{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20  words:\n",
      "repubblica -> 110\n",
      "stato -> 82\n",
      "presidente -> 71\n",
      "consiglio -> 58\n",
      "regione -> 57\n",
      "cost -> 55\n",
      "comma -> 53\n",
      "regioni -> 52\n",
      "camere -> 50\n",
      "leggi -> 49\n",
      "costituzione -> 48\n",
      "diritto -> 44\n",
      "secondo -> 42\n",
      "regionale -> 41\n",
      "funzioni -> 41\n",
      "articolo -> 40\n",
      "testo -> 39\n",
      "governo -> 37\n",
      "possono -> 37\n",
      "camera -> 35\n",
      "esercizio -> 34\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "\n",
    "# open the text file to analyse\n",
    "text = open(\"/Users/roberto/Desktop/UNI 3^ ANNO/algoritmi/programmi.py/4Strutture dati-20231221/test_file.txt\", \"r\").read()\n",
    "# create a dictionary for words\n",
    "word_count_dict = dict()\n",
    "\n",
    "# create a list for stop words\n",
    "stop_word_list= []\n",
    "# open the stop word text file\n",
    "stop_word_file = open(\"/Users/roberto/Desktop/UNI 3^ ANNO/algoritmi/programmi.py/4Strutture dati-20231221/italian_stop_words.txt\", \"r\")\n",
    "# load all stop words in the list stop_word_list\n",
    "stop_word_text =  stop_word_file.read()\n",
    "for stop_word in stop_word_text.split():\n",
    "    stop_word_list.append(stop_word)\n",
    "\n",
    "# change the text to be analysed to lowercase to avoid case mismatch\n",
    "text = text.lower()\n",
    "\n",
    "# remove unwanted chars (i.e. all chars except {a, ..., z} and {à, è, é, ì, ò, ù})\n",
    "unwanted_char_list = list(string.ascii_lowercase + \"àèéìòù\")\n",
    "clean_text = \"\"\n",
    "for char in text:\n",
    "    # add the char if it is not included in the unwanted set, otherwise add a whitespace\n",
    "    if char in unwanted_char_list:\n",
    "        clean_text = clean_text + char\n",
    "    else:\n",
    "        clean_text = clean_text + \" \"\n",
    "\n",
    "# split into words (spliting is based on withespaces)\n",
    "words = clean_text.split()\n",
    "# for each word in text:\n",
    "for word in words:\n",
    "    # removes stop word and numeric words\n",
    "    if word not in stop_word_list:\n",
    "        # check if the word is already in dictionary\n",
    "        if word in word_count_dict:\n",
    "            # increment count of word by 1\n",
    "            word_count_dict[word] = word_count_dict[word] + 1\n",
    "        else:\n",
    "            # add the word to dictionary with count 1\n",
    "            word_count_dict[word] = 1\n",
    "\n",
    "# print top x words sorted by count\n",
    "top_x = 20\n",
    "word_count_list_sorted = sorted(word_count_dict.items(), key=lambda kv: kv[1])\n",
    "print(\"Top\", top_x, \" words:\")\n",
    "for i, elem in enumerate(reversed(word_count_list_sorted)) :\n",
    "    print(elem[0], \"->\", elem[1])\n",
    "    if i == top_x:\n",
    "        break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
